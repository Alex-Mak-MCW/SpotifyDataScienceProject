{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebase for Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things that have done\n",
    "1. load raw data\n",
    "2. data transformation (numeric and categorcial data)\n",
    "3. univariate and multivariate exploratory data analysis (EDA)\n",
    "4. correlation analysis\n",
    "5. text preprocessing using NLP techniques\n",
    "6. data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Data/complete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null and duplicate values\n",
    "\n",
    "# identify null data\n",
    "print(\"Number of null values in the dataset:\\n{0}\".format(df.isnull().sum())) \n",
    "# There are 26 missing value in lyrics--> will be handled\n",
    "\n",
    "# identify duplciate data\n",
    "print(\"\\nNumber of duplicate data in the dataset:\\n{0}\".format(df.duplicated().sum())) # No duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duration and duration_ms\n",
    "print(df['duration'])\n",
    "print(df['duration_ms'])\n",
    "\n",
    "# drop duration_ms\n",
    "df.drop(columns=['duration_ms'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop object columns: track_href, analysis_url, Track ID, id, uri, and type\n",
    "df.drop(columns=['track_href', 'analysis_url', 'track_ID', 'id', 'uri', 'type'], inplace=True)\n",
    "\n",
    "print(df.shape) # (2457, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop preview url\n",
    "# drop object columns: track_href, analysis_url, Track ID, id, uri, and type\n",
    "df.drop(columns=['preview_url'], inplace=True)\n",
    "\n",
    "print(df.shape) # (2457, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPPROCESSING (Part 1: numbers)\n",
    "\n",
    "# 1. binary encode boolean feature (explicit) \n",
    "# print(df['explicit'].value_counts())\n",
    "df['explicit']=df['explicit'].astype(int)\n",
    "# print(df['explicit'].value_counts()) # 1719 F (0), 738 T (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Descriptive/ Summary statistics for continuous data (15 columns)\n",
    "# numeric_summary=df.describe().style.set_caption('Summary Statistics for Continuous Data').format(precision=2).background_gradient(cmap='Blues')\n",
    "# display(numeric_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPPROCESSING (Part 2: TEXT)\n",
    "\n",
    "# check the object columns\n",
    "# Select columns of type 'object'\n",
    "object_columns = df.select_dtypes(include=['object']) # 5 columns left\n",
    "# print(object_columns)\n",
    "# Artist, Track, Release Date, Album Name, Lyrics\n",
    "\n",
    "# Convert object column to datetime\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "print(df['release_date']) # success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null and duplicate values\n",
    "\n",
    "# identify null data\n",
    "print(\"Number of null values in the dataset:\\n{0}\".format(df.isnull().sum())) \n",
    "# There are 26 missing value in lyrics--> will be handled\n",
    "\n",
    "# identify duplciate data\n",
    "print(\"\\nNumber of duplicate data in the dataset:\\n{0}\".format(df.duplicated().sum())) # 23 duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the 52 songs\n",
    "\n",
    "# DATA has 1000,20: 20=15(int/float)+4(object/string)+1(datetime)\n",
    "\n",
    "import lyricsgenius\n",
    "genius=lyricsgenius.Genius(\"jCaG2w1CCDLgiXm8JGamJxOdA1Z8eMEKYJhjecctVLM270hsAJkwDBReNzhbZ4Fg\", retries=3)\n",
    "\n",
    "# try to 26 lyrics\n",
    "# find the songs with missing values\n",
    "missing_index = df[df.isnull().any(axis=1)].index\n",
    "\n",
    "# print(\"Indexes of rows with missing values:\")\n",
    "missing_index_list=list(missing_index)\n",
    "# print(missing_index_list) # [75, 80, 147, 168, 214, 254, 395, 399, 448, 506, 516, 539, 615, 645, 648, 649, 664, 714, 761, 778, 805, 808, 811, 815, 817, 829]\n",
    "\n",
    "# impute it manually with the website\n",
    "for i in missing_index_list:\n",
    "    try:\n",
    "        # Attempt to search for the song\n",
    "        song = genius.search_song(df.loc[i, 'track_name'].split(\"(\", 1)[0], df.loc[i, 'artist'])\n",
    "        if song:\n",
    "            # IMPUTE IT \n",
    "            df.loc[i, 'lyrics']=song.lyrics\n",
    "            # temp+=1\n",
    "        else:\n",
    "            song2 = genius.search_song(df.loc[i, 'track_name'].split()[0], df.loc[i, 'artist'])\n",
    "            if song2:\n",
    "                # IMPUTE IT \n",
    "                df.loc[i, 'lyrics']=song2.lyrics\n",
    "                # temp+=1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of null values in the dataset:\\n{0}\".format(df.isnull().sum())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the reamining songs:\n",
    "\n",
    "# missing_index = df[df.isnull().any(axis=1)].index\n",
    "\n",
    "# print(\"Indexes of rows with missing values:\")\n",
    "missing_index_list=[210, 1471, 1668, 2191]\n",
    "# print(missing_index_list)\n",
    "\n",
    "# 210 is don omar as artist\n",
    "# the rest are just title\n",
    "# 1668 snowfall\n",
    "# 2191 river flows in you\n",
    "# 1471 is intro\n",
    "# df.loc[210, 'track_name']\n",
    "\n",
    "\n",
    "# manual imputation by changing artist name\n",
    "# impute it manually with the website\n",
    "for i in missing_index_list:\n",
    "    if i==210:\n",
    "        artist=\"Don Omar\"\n",
    "        # song = genius.search_song('danza kuduro', \"Don Omar\")\n",
    "        # if song:\n",
    "        #     # IMPUTE IT \n",
    "        #     df.loc[i, 'Lyrics']=song.lyrics\n",
    "    elif i==1471: # artist name\n",
    "        artist=\"The xx\"\n",
    "    elif i==1668:\n",
    "        artist=\"Ã˜neheart & reidenshi\"\n",
    "    elif i==2191:\n",
    "        artist=\"Yiruma\"\n",
    "    try:\n",
    "        # Attempt to search for the song\n",
    "        song = genius.search_song(df.loc[i, 'track_name'].split()[0], artist=artist)\n",
    "        if song:\n",
    "            # IMPUTE IT \n",
    "            df.loc[i, 'lyrics']=song.lyrics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "print(df[df.isnull().any(axis=1)].index)\n",
    "\n",
    "# remaining ones are instrumental + korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate values\n",
    "# print(\"\\nNumber of duplicate data in the dataset:\\n{0}\".format(df.duplicated().sum())) # No duplicate values\n",
    "\n",
    "df[df.duplicated()]\n",
    "# habits, don't blame me(858 or 1117), (1560 or 1561)\n",
    "\n",
    "# drop 858 and 1560\n",
    "\n",
    "df.drop([858, 1560],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNumber of duplicate data in the dataset:\\n{0}\".format(df.duplicated().sum())) # 23 duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "* provide descriptive statistics \n",
    "\n",
    "* univariate\n",
    "\n",
    "* outlier detection through boxplots for continuous data\n",
    "* frequency analysis through barplot for discrete data\n",
    "* outlier and unknown removal\n",
    "\n",
    "* multivariate: pairwise scaterplot(predictor vs y) to see trends, correlation analysis to check multicolinarity (heatmaps)\n",
    "\n",
    "* Standarizations and multicolinearity?\n",
    "\n",
    "* write conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive/ Summary statistics for continuous data (15 columns)\n",
    "numeric_summary=df.describe().style.set_caption('Summary Statistics for Continuous Data').format(precision=2).background_gradient(cmap='Blues')\n",
    "display(numeric_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency analysis\n",
    "import seaborn as sns\n",
    "\n",
    "# frequency analysis for categorical variable and encoded numerical variables:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# artist is uniformly distributed\n",
    "# track is an issue now\n",
    "# album is interesing though\n",
    "\n",
    "test=df['album'].value_counts().head(10)\n",
    "\n",
    "test_df=test.reset_index()\n",
    "test_df.columns=['Category', 'Frequency']\n",
    "\n",
    "# Plot the frequency distribution using a boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(y='Frequency', x='Category' ,data=test_df)\n",
    "plt.xlabel('Album')\n",
    "plt.title('Frequency Distribution of Album')\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df['track_name'].value_counts().head(10)\n",
    "\n",
    "test_df=test.reset_index()\n",
    "test_df.columns=['Category', 'Frequency']\n",
    "\n",
    "# Plot the frequency distribution using a boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(y='Frequency', x='Category' ,data=test_df)\n",
    "plt.xlabel('Track')\n",
    "plt.title('Frequency Distribution of Track')\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df['artist'].value_counts().head(10)\n",
    "\n",
    "test_df=test.reset_index()\n",
    "test_df.columns=['Category', 'Frequency']\n",
    "\n",
    "# Plot the frequency distribution using a boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(y='Frequency', x='Category' ,data=test_df)\n",
    "plt.xlabel('Artist')\n",
    "plt.title('Frequency Distribution of Artist')\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate EDA\n",
    "# numerical analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
    "\n",
    "# print(df.select_dtypes(include=['number']).columns)\n",
    "\n",
    "# exclude poutcome and y\n",
    "# Plot each numeric column's box plot\n",
    "for i, column in enumerate(df.select_dtypes(include=['number']).columns):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    if row < num_rows and col < num_cols:\n",
    "        sns.boxplot(x=df[column], ax=axes[row, col])\n",
    "        axes[row, col].set_title(column)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate EDA (takes 3 min)\n",
    "\n",
    "# Multivariate analysis- print pairwise scatterplot for each x to y\n",
    "# Warning: takes a long time to run\n",
    "\n",
    "# import seaborn as sns\n",
    "sns.pairplot(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X is your DataFrame containing numeric features\n",
    "\n",
    "# Select only numeric features\n",
    "numeric_features = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create pairplot\n",
    "sns.pairplot(numeric_features)\n",
    "plt.title('Pairplot of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X is your DataFrame containing numeric features\n",
    "\n",
    "# Select only numeric features\n",
    "numeric_features = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_features.corr()\n",
    "\n",
    "# Display the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from langdetect import detect\n",
    "from contractions import fix\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Download NLTK resources if not already installed\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to check if the text is in English\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False  # Return False if language detection fails\n",
    "\n",
    "# Initialize BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def clean_lyrics(lyrics):\n",
    "    # Check if the lyrics are a string\n",
    "    if isinstance(lyrics, str):\n",
    "        if len(lyrics.split('\\n', 1)) > 1:\n",
    "            # If there are at least two elements after split, get the second element and omit the last 8 characters\n",
    "            cleaned_lyrics = lyrics.split('\\n', 1)[1][:-8]\n",
    "            # Remove square brackets and the content inside them\n",
    "            cleaned_lyrics = re.sub(r'\\[.*?\\]', '', cleaned_lyrics)\n",
    "            # Remove round brackets but keep their content intact, replace \"\\n\" with \" \", and lowercase every word\n",
    "            cleaned_lyrics = re.sub(r'\\(|\\)', '', cleaned_lyrics).replace(\"\\n\", \" \").lower()\n",
    "\n",
    "            # Remove punctuation\n",
    "            cleaned_lyrics = re.sub(r'[^\\w\\s#]', '', cleaned_lyrics)\n",
    "\n",
    "            # Tokenization using BertTokenizer\n",
    "            tokens = tokenizer.tokenize(cleaned_lyrics)\n",
    "\n",
    "            # Join tokens back into a string\n",
    "            cleaned_lyrics = ' '.join(tokens)\n",
    "\n",
    "            # strip the spaces\n",
    "            cleaned_lyrics = cleaned_lyrics.strip()\n",
    "\n",
    "            # Check if the cleaned lyrics are in English\n",
    "            return cleaned_lyrics if is_english(cleaned_lyrics) else ''\n",
    "        else:\n",
    "            return ''  # Return None if split_lyrics has fewer than 2 elements\n",
    "    else:\n",
    "        return ''  # Return None if lyrics is not a string\n",
    "\n",
    "# Load and preprocess data\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export it\n",
    "df.to_csv('processed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
