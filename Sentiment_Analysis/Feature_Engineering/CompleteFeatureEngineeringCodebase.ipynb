{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading text-processed data\n",
    "# df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Data/NLP_processed_text.csv\", encoding='utf-8')\n",
    "\n",
    "# df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Data/text_processed_data.csv\", encoding='utf-8')\n",
    "\n",
    "# read test dataset\n",
    "# df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Data/PROTO_text.csv\", encoding='utf-8')\n",
    "\n",
    "# reading data directly from textpreprocessing.ipynb\n",
    "# df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Sentiment_Analysis/Final_processed_text.csv\", encoding='utf-8')\n",
    "\n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/Alex-Mak-MCW/SpotifyDataScienceProject/main/Data/Sentiment_Analysis/test_English.csv\", encoding='Utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.730  ...    -5.934   1.0       0.0598       0.00146          0.000095   \n",
       "1   0.652  ...    -3.183   0.0       0.0802       0.58100          0.000000   \n",
       "2   0.405  ...    -5.679   1.0       0.0319       0.75100          0.000000   \n",
       "3   0.522  ...    -4.368   1.0       0.0575       0.53300          0.000000   \n",
       "4   0.731  ...    -5.338   0.0       0.0557       0.34200          0.001010   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  mood  \n",
       "0    0.0897    0.334  171.005             4.0     0  \n",
       "1    0.0931    0.931   95.977             4.0     1  \n",
       "2    0.1050    0.446  109.891             4.0     0  \n",
       "3    0.0685    0.925   89.960             4.0     1  \n",
       "4    0.3110    0.662  173.930             4.0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify dataset\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 1: \n",
    "### Count-vectorizer (CV) + Term Frequency-Inverse document Frequency (TF-IDF)\n",
    "\n",
    "#### Count Vectorizer (CV)\n",
    "* Convert text to array of token counts\n",
    "* Create a vocabulary of all unique words, then count the frequency for each word.\n",
    "* Helps to to learn patterns with positive or negative sentiment based on word frequency.\n",
    "##### Pros\n",
    "* Easy, fast, basic\n",
    "##### Cons\n",
    "* Ignore word context, large feature space, common words too heavy in weighting. \n",
    "\n",
    "#### Term Frequency-Inverse document Frequency (TF-IDF)\n",
    "* Extends CV, consider the importance of a word in the entire text.\n",
    "* Determine how unique/common the term across all text.\n",
    "* Weight shift common and rare words\n",
    "##### Pros\n",
    "* Balance word frequency and importance\n",
    "##### Cons\n",
    "* Still ignore word context, computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of df\n",
    "\n",
    "df_CV_TF_IDF=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Custom transformer to select text column\n",
    "get_text_data = FunctionTransformer(lambda x: x['lyrics'], validate=False)\n",
    "\n",
    "# Pipeline for text processing\n",
    "text_pipeline = Pipeline([\n",
    "    ('selector', get_text_data),\n",
    "    ('features', FeatureUnion([\n",
    "        ('tfidf', Pipeline([\n",
    "            ('count', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ]))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Get the feature names\n",
    "text_features = text_pipeline.fit_transform(df_CV_TF_IDF)\n",
    "feature_names = text_pipeline.named_steps['features'].transformer_list[0][1].named_steps['count'].get_feature_names_out()\n",
    "\n",
    "# Omit the last 5 feature names\n",
    "clean_feature_names = feature_names\n",
    "# clean_feature_names = feature_names[:-25]\n",
    "\n",
    "# Create a new CountVectorizer with the filtered feature names\n",
    "clean_count_vectorizer = CountVectorizer(vocabulary=clean_feature_names)\n",
    "\n",
    "# Update the pipeline with the new CountVectorizer\n",
    "text_pipeline.named_steps['features'].transformer_list[0] = ('tfidf', Pipeline([\n",
    "    ('count', clean_count_vectorizer),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "]))\n",
    "\n",
    "# Transform text data again with the updated pipeline\n",
    "text_features = text_pipeline.fit_transform(df_CV_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaah', 'aaaall', ..., 'zuli', 'zz', 'zzzzzzz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names from TF-IDF\n",
    "tfidf_vectorizer = text_pipeline.named_steps['features'].transformer_list[0][1].named_steps['count']\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aaaah' 'aaaall' ... 'zuli' 'zz' 'zzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "# Access CountVectorizer\n",
    "count_vectorizer = text_pipeline.named_steps['features'].transformer_list[0][1].named_steps['count']\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of both DataFrames\n",
    "df_CV_TF_IDF.reset_index(drop=True, inplace=True)\n",
    "# Set feature names as column names for text_features_df\n",
    "text_features_df = pd.DataFrame(text_features.toarray(), columns=tfidf_feature_names)\n",
    "\n",
    "# Perform a left merge to align rows properly\n",
    "df_CV_TF_IDF = pd.merge(df_CV_TF_IDF, text_features_df, left_index=True, right_index=True, how='left', suffixes=('', '_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 13104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomin</th>\n",
       "      <th>zoowap</th>\n",
       "      <th>ztrip</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zulema</th>\n",
       "      <th>zuli</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  zoo  zoom  zoomin  zoowap  ztrip  zucchini  zulema  zuli   zz  \\\n",
       "0   0.730  ...  0.0   0.0     0.0     0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "1   0.652  ...  0.0   0.0     0.0     0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "2   0.405  ...  0.0   0.0     0.0     0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "3   0.522  ...  0.0   0.0     0.0     0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "4   0.731  ...  0.0   0.0     0.0     0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "\n",
       "   zzzzzzz  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 13104 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_CV_TF_IDF.shape)\n",
    "df_CV_TF_IDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export feature engineered dataset\n",
    "df_CV_TF_IDF.to_csv('CV_and_TFIDF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 2: \n",
    "### Character Level N-Grams (Chosen N=3)\n",
    "\n",
    "* Sequence of N items in a text (bigrams, trigrams etc)\n",
    "##### Pros\n",
    "* Pros: Capture word context and sequence, capture common phrase that indicate sentiment\n",
    "##### Cons\n",
    "* Expensive with large N, prone to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate character-level n-grams\n",
    "def generate_char_ngrams(text_series, n):\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(n, n))\n",
    "    # Fit and transform the text data to get the n-grams\n",
    "    ngrams_matrix = vectorizer.fit_transform(text_series)\n",
    "    # Get the feature names (n-grams)\n",
    "    ngrams = vectorizer.get_feature_names_out()\n",
    "    # Convert the sparse matrix to a dense one and create a DataFrame\n",
    "    ngrams_df = pd.DataFrame(ngrams_matrix.toarray(), columns=ngrams)\n",
    "    return ngrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_N_Grams=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.730  ...    -5.934   1.0       0.0598       0.00146          0.000095   \n",
       "1   0.652  ...    -3.183   0.0       0.0802       0.58100          0.000000   \n",
       "2   0.405  ...    -5.679   1.0       0.0319       0.75100          0.000000   \n",
       "3   0.522  ...    -4.368   1.0       0.0575       0.53300          0.000000   \n",
       "4   0.731  ...    -5.338   0.0       0.0557       0.34200          0.001010   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  mood  \n",
       "0    0.0897    0.334  171.005             4.0     0  \n",
       "1    0.0931    0.931   95.977             4.0     1  \n",
       "2    0.1050    0.446  109.891             4.0     0  \n",
       "3    0.0685    0.925   89.960             4.0     1  \n",
       "4    0.3110    0.662  173.930             4.0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_N_Grams.shape)\n",
    "df_N_Grams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 N=1 gram (Unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1-grams (Unigrams)\n",
    "\n",
    "# call generate function\n",
    "char_1grams_df = generate_char_ngrams(df_N_Grams['lyrics'], 1)\n",
    "# Concatenate the n-grams DataFrame with the original DataFrame\n",
    "df_with_1grams = pd.concat([df_N_Grams.reset_index(drop=True), char_1grams_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  q   r   s   t   u   v   w  x   y  z  \n",
       "0   0.730  ...  0  18  22  30  18   5   7  0  16  0  \n",
       "1   0.652  ...  0  48  59  66  23  44  35  2  15  2  \n",
       "2   0.405  ...  0  23  33  32  28  10   8  0  11  1  \n",
       "3   0.522  ...  2  29  48  40  31   9  26  0  20  0  \n",
       "4   0.731  ...  0  17  13  21   4   5  23  0   7  0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_with_1grams.shape)\n",
    "df_with_1grams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export unigram feature engineered dataset\n",
    "df_with_1grams.to_csv('1_Grams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 N=2 gram (Bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2-grams (Bigram)\n",
    "# call generate function\n",
    "char_2grams_df = generate_char_ngrams(df_N_Grams['lyrics'], 2)\n",
    "# Concatenate the n-grams DataFrame with the original DataFrame\n",
    "df_with_2grams = pd.concat([df_N_Grams.reset_index(drop=True), char_2grams_df], axis=1)\n",
    "\n",
    "# # Generate 3-grams (Trigram)\n",
    "# # call generate function\n",
    "# char_2gram_df = generate_char_ngrams(df_N_Grams['lyrics'], 2)\n",
    "# # Concatenate the n-grams DataFrame with the original DataFrame\n",
    "# df_with_2gram = pd.concat([df_N_Grams.reset_index(drop=True), char_2gram_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 675)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>zl</th>\n",
       "      <th>zm</th>\n",
       "      <th>zn</th>\n",
       "      <th>zo</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  zl  zm  zn  zo  zt  zu  zv  zw  zy  zz  \n",
       "0   0.730  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0.652  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "2   0.405  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "3   0.522  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "4   0.731  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 675 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_with_2grams.shape)\n",
    "df_with_2grams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export unigram feature engineered dataset\n",
    "df_with_2grams.to_csv('2_Grams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 N=3 gram (Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3-grams (trigrams)\n",
    "char_3grams_df = generate_char_ngrams(df_N_Grams['lyrics'], 3)\n",
    "\n",
    "# print(char_3grams_df)\n",
    "\n",
    "# Optionally, concatenate the n-grams DataFrame with the original DataFrame\n",
    "df_with_3grams = pd.concat([df_N_Grams.reset_index(drop=True), char_3grams_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 6835)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>zyf</th>\n",
       "      <th>zyn</th>\n",
       "      <th>zz</th>\n",
       "      <th>zza</th>\n",
       "      <th>zzc</th>\n",
       "      <th>zze</th>\n",
       "      <th>zzi</th>\n",
       "      <th>zzl</th>\n",
       "      <th>zzo</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6835 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  zyf  zyn  zz   zza  zzc  zze  zzi  zzl  zzo  zzz  \n",
       "0   0.730  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0.652  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0.405  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3   0.522  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4   0.731  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 6835 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_with_3grams.shape)\n",
    "df_with_3grams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export feature engineered dataset\n",
    "df_with_3grams.to_csv('3_Grams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 3: \n",
    "### Word Embeddings\n",
    "\n",
    "* Represent word in a continuous vector space, to capture semantic and syntactic meaning of words so similar meaning are place closely in a vector space\n",
    "\n",
    "#### Contextual Relationships\n",
    "* Train word embedding on large corpora where each word's context is considered\n",
    "* Words with similar context -> similar vectors \n",
    "* Application: Word2Vec, FastText, GloVe (mention later)\n",
    "\n",
    "\n",
    "#### Word2Vec uses...\n",
    "* Continuous Bag of Words (CBOW): represent text by the frequency of each word in the library, then predicts a target word based on its surronding context word\n",
    "* Skip-gram: predict context words from a rarget word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Embeddings=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 FastText (currently only on google Colab)\n",
    "* Extension of Word2Vec by Facebook\n",
    "* Considers subword information (N-grams)\n",
    "* Effective for morphologically rich langauges and rich words.\n",
    "\n",
    "##### Pros\n",
    "* Capture subword info, better handle rare words\n",
    "* generate meaning embeddings even for misspelled/ morphologically rich words\n",
    "\n",
    "##### Cons\n",
    "* May not capture deep semantic context\n",
    "* Pre-trained models may not fir specific domain vocab without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FastText=df_Embeddings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Assuming df_fast_text is a pandas DataFrame containing the lyrics\n",
    "# Tokenize text column\n",
    "df_fast_text['tokenized_lyrics'] = df_fast_text['lyrics'].apply(lambda x: x.split())\n",
    "\n",
    "# Prepare corpus\n",
    "corpus = df_fast_text['tokenized_lyrics'].tolist()\n",
    "\n",
    "# Initialize and train FastText model\n",
    "fasttext_model = FastText(vector_size=100, window=5, min_count=1)\n",
    "fasttext_model.build_vocab(corpus_iterable=corpus)\n",
    "fasttext_model.train(corpus_iterable=corpus, total_examples=len(corpus), epochs=10)\n",
    "\n",
    "# Example: Get vector for a word\n",
    "word_vector = fasttext_model.wv['document']\n",
    "\n",
    "# Example: Get vector for a sentence (average of word vectors)\n",
    "def get_sentence_vector(sentence):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "    return sum(word_vectors) / len(word_vectors) if word_vectors else []\n",
    "\n",
    "# Assuming there's a text column in df_fast_text\n",
    "df_fast_text['fasttext_vector'] = df_fast_text['lyrics'].apply(get_sentence_vector)\n",
    "\n",
    "# Print the resulting vectors\n",
    "print(df_fast_text['fasttext_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_text.to_csv(\"FastText.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 GloVe (GLobal Vectors for Word Representation)\n",
    "##### (currently not avaliable on local machine, can try Colab)\n",
    "\n",
    "* Build word vectors by aggregate global word-word co-occurrence statistics from a corpus.\n",
    "* Provides fixed-size dense vectors that capture semantic relationships between words. \n",
    "* Convert words into meaningful numerical representations that reflect their sentiment-related properties.\n",
    "\n",
    "##### Pros\n",
    "* Pre-trained on large corpora, offering good generalization.\n",
    "* Computationally efficient for downstream tasks.\n",
    "\n",
    "##### Cons\n",
    "* Static embeddings (same vector for a word regardless of context).\n",
    "* May not handle polysemy (words with multiple meanings) well.\n",
    "* Compuationally expensive to train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 BERT (Bidirectional Encoder Representations from Transformers):\n",
    "\n",
    "##### Uses Contextual Embeddings\n",
    "* Represent words in a way that depends on the context they appear.\n",
    "* Provide different representation for words based on their surrounding words\n",
    "* Capture dynamic meaning of words\n",
    "\n",
    "##### What it does...\n",
    "\n",
    "* Built based on transfromer architecture \n",
    "* Bidirectional approach (looks at context ledt and right) to learn representation of each word.\n",
    "\n",
    "##### Pros\n",
    "* Generates context-aware embeddings, improving understanding of word meaning in context.\n",
    "* State-of-the-art performance in sentiment analysis and other NLP tasks.\n",
    "* Fine-tunable for specific tasks, enhancing adaptability.\n",
    "\n",
    "##### Cons\n",
    "* Computationally expensive to train and apply.\n",
    "* Requires large amounts of memory and processing power.\n",
    "* Pre-trained models might need substantial fine-tuning for specific domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BERT=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.730  ...    -5.934   1.0       0.0598       0.00146          0.000095   \n",
       "1   0.652  ...    -3.183   0.0       0.0802       0.58100          0.000000   \n",
       "2   0.405  ...    -5.679   1.0       0.0319       0.75100          0.000000   \n",
       "3   0.522  ...    -4.368   1.0       0.0575       0.53300          0.000000   \n",
       "4   0.731  ...    -5.338   0.0       0.0557       0.34200          0.001010   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  mood  \n",
       "0    0.0897    0.334  171.005             4.0     0  \n",
       "1    0.0931    0.931   95.977             4.0     1  \n",
       "2    0.1050    0.446  109.891             4.0     0  \n",
       "3    0.0685    0.925   89.960             4.0     1  \n",
       "4    0.3110    0.662  173.930             4.0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_BERT.shape)\n",
    "df_BERT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [-0.051606975, 0.059196685, 0.8179265, -0.1613...\n",
      "1       [-0.25514305, -0.26647133, 0.80487204, -0.1589...\n",
      "2       [-0.20082025, -0.05428033, 0.6784714, 0.129567...\n",
      "3       [-0.1918617, 0.11497808, 0.6076808, -0.1166371...\n",
      "4       [-0.05787892, 0.21525346, 1.042814, -0.1600381...\n",
      "                              ...                        \n",
      "1616    [-0.16968827, 0.0020094733, 0.61205995, -0.145...\n",
      "1617    [0.04698473, 0.037607603, 0.89777786, -0.12191...\n",
      "1618    [-0.45085692, 0.19648445, 1.0196003, -0.113810...\n",
      "1619    [-0.3800811, -0.15651153, 0.7316858, -0.078895...\n",
      "1620    [-0.24994217, 0.067083925, 0.606919, -0.025780...\n",
      "Name: bert_vector, Length: 1621, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example: Get vector for a sentence using BERT\n",
    "def get_bert_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "df_BERT['bert_vector'] = df_BERT['lyrics'].apply(get_bert_embedding)\n",
    "print(df_BERT['bert_vector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export BERT dataset\n",
    "df_BERT.to_csv(\"BERT_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 4: \n",
    "### Sentiment Intensity Analyzer (VADER)\n",
    "\n",
    "#### Valence Aware Dictionary and Sentiment Reasoner\n",
    "\n",
    "* Lexicon & rule-based sentiment analusis tool.\n",
    "* Provide sentiment score (Positive, negative, neutral, compound) based on intensity of words & their context.\n",
    "* Can be used alone or with other feature engineering tools for NLP tasks.\n",
    "\n",
    "##### Pros\n",
    "* Designed for sentiment analysis, especially in social media contexts.\n",
    "* Easy to use, integrate, and be interpretted.\n",
    "* Effective for short and informal texts.\n",
    "\n",
    "##### Cons\n",
    "* Rule-based approach may not generalize well to all types of text.\n",
    "* Limited in handling complex sentences and sarcasm.\n",
    "* Performance may degrade on domain-specific or longer texts without additional tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VADER=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.730  ...    -5.934   1.0       0.0598       0.00146          0.000095   \n",
       "1   0.652  ...    -3.183   0.0       0.0802       0.58100          0.000000   \n",
       "2   0.405  ...    -5.679   1.0       0.0319       0.75100          0.000000   \n",
       "3   0.522  ...    -4.368   1.0       0.0575       0.53300          0.000000   \n",
       "4   0.731  ...    -5.338   0.0       0.0557       0.34200          0.001010   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  mood  \n",
       "0    0.0897    0.334  171.005             4.0     0  \n",
       "1    0.0931    0.931   95.977             4.0     1  \n",
       "2    0.1050    0.446  109.891             4.0     0  \n",
       "3    0.0685    0.925   89.960             4.0     1  \n",
       "4    0.3110    0.662  173.930             4.0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_VADER.shape)\n",
    "df_VADER.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to apply VADER and return the sentiment scores\n",
    "def get_vader_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return pd.Series(scores)\n",
    "\n",
    "# Apply the function to the text column and create new columns for each score\n",
    "df_VADER[['negative', 'neutral', 'positive', 'compound']] = df_VADER['lyrics'].apply(get_vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.9852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.9538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  instrumentalness  liveness  valence    tempo  time_signature  \\\n",
       "0   0.730  ...          0.000095    0.0897    0.334  171.005             4.0   \n",
       "1   0.652  ...          0.000000    0.0931    0.931   95.977             4.0   \n",
       "2   0.405  ...          0.000000    0.1050    0.446  109.891             4.0   \n",
       "3   0.522  ...          0.000000    0.0685    0.925   89.960             4.0   \n",
       "4   0.731  ...          0.001010    0.3110    0.662  173.930             4.0   \n",
       "\n",
       "   mood  negative  neutral  positive  compound  \n",
       "0     0     0.141    0.726     0.133   -0.3182  \n",
       "1     1     0.009    0.574     0.417    0.9996  \n",
       "2     0     0.135    0.580     0.285    0.9852  \n",
       "3     1     0.208    0.648     0.144   -0.8979  \n",
       "4     1     0.000    0.753     0.247    0.9538  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_VADER.shape)\n",
    "df_VADER.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VADER.head().to_csv(\"VADER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 5: \n",
    "### LDA (topic modeling)\n",
    "* Identifies topics in a collection of documents by observing the distribution of words.\n",
    "* Discover underlying themes or topics within text data, then use those themes/ topics as additional features.\n",
    "* Those themes/ topics might be correlated to sentiments.\n",
    "\n",
    "##### Pros\n",
    "* Unsupervised method to discover hidden topics in text.\n",
    "* Provide insights into the thematic structure of a corpus.\n",
    "* Useful for exploring and summarizing large text datasets.\n",
    "\n",
    "##### Cons\n",
    "* Assumes a fixed number of topics, hence requiring domain knowledge or trial-and-error to set.\n",
    "* Topics may not always correspond to clear or coherent themes.\n",
    "* Computationally intensive especially for large text.\n",
    "* Not specifically tailored for sentiment analysis, requiring additional steps to link topics to sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LDA=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.730  ...    -5.934   1.0       0.0598       0.00146          0.000095   \n",
       "1   0.652  ...    -3.183   0.0       0.0802       0.58100          0.000000   \n",
       "2   0.405  ...    -5.679   1.0       0.0319       0.75100          0.000000   \n",
       "3   0.522  ...    -4.368   1.0       0.0575       0.53300          0.000000   \n",
       "4   0.731  ...    -5.338   0.0       0.0557       0.34200          0.001010   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  mood  \n",
       "0    0.0897    0.334  171.005             4.0     0  \n",
       "1    0.0931    0.931   95.977             4.0     1  \n",
       "2    0.1050    0.446  109.891             4.0     0  \n",
       "3    0.0685    0.925   89.960             4.0     1  \n",
       "4    0.3110    0.662  173.930             4.0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_LDA.shape)\n",
    "df_LDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexmak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexmak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.107*\"ooh\" + 0.059*\"danc\" + 0.046*\"life\" + 0.028*\"cri\" + 0.024*\"whole\" + 0.024*\"done\" + 0.022*\"move\" + 0.022*\"lord\" + 0.020*\"god\" + 0.020*\"water\"')\n",
      "(1, '0.052*\"know\" + 0.034*\"say\" + 0.030*\"feel\" + 0.025*\"ey\" + 0.020*\"time\" + 0.020*\"think\" + 0.020*\"one\" + 0.019*\"would\" + 0.018*\"like\" + 0.018*\"could\"')\n",
      "(2, '0.219*\"hey\" + 0.063*\"heaven\" + 0.036*\"sick\" + 0.035*\"forc\" + 0.023*\"wave\" + 0.020*\"silver\" + 0.015*\"dollar\" + 0.015*\"fresh\" + 0.014*\"lot\" + 0.014*\"rhythm\"')\n",
      "(3, '0.102*\"long\" + 0.035*\"cloth\" + 0.030*\"gaga\" + 0.024*\"moonlight\" + 0.023*\"hoo\" + 0.020*\"reckless\" + 0.018*\"cheap\" + 0.015*\"kitchen\" + 0.014*\"nanana\" + 0.011*\"poison\"')\n",
      "(4, '0.143*\"okay\" + 0.078*\"somebodi\" + 0.060*\"fire\" + 0.023*\"stori\" + 0.022*\"town\" + 0.020*\"messag\" + 0.020*\"beneath\" + 0.020*\"somewher\" + 0.019*\"blow\" + 0.017*\"flower\"')\n",
      "(5, '0.079*\"yeah\" + 0.076*\"want\" + 0.060*\"got\" + 0.049*\"go\" + 0.035*\"babi\" + 0.032*\"like\" + 0.029*\"girl\" + 0.025*\"get\" + 0.015*\"uh\" + 0.014*\"know\"')\n",
      "(6, '0.161*\"love\" + 0.062*\"let\" + 0.054*\"us\" + 0.046*\"day\" + 0.035*\"ah\" + 0.034*\"give\" + 0.032*\"good\" + 0.027*\"everi\" + 0.025*\"littl\" + 0.021*\"need\"')\n",
      "(7, '0.029*\"nigga\" + 0.025*\"like\" + 0.021*\"fuck\" + 0.019*\"bitch\" + 0.017*\"hit\" + 0.016*\"ayi\" + 0.016*\"rock\" + 0.016*\"boy\" + 0.014*\"got\" + 0.013*\"gon\"')\n",
      "(8, '0.102*\"oh\" + 0.033*\"come\" + 0.033*\"see\" + 0.031*\"like\" + 0.030*\"look\" + 0.023*\"way\" + 0.020*\"never\" + 0.016*\"back\" + 0.015*\"low\" + 0.014*\"outsid\"')\n",
      "(9, '0.028*\"sugar\" + 0.023*\"citi\" + 0.022*\"choppa\" + 0.022*\"purpl\" + 0.021*\"nle\" + 0.020*\"angel\" + 0.019*\"feat\" + 0.018*\"drove\" + 0.014*\"speed\" + 0.012*\"livin\"')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df_LDA['processed_lyrics'] = df_LDA['lyrics'].apply(preprocess)\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df_LDA['processed_lyrics'])\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in df_LDA['processed_lyrics']]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=10, random_state=42, update_every=1, chunksize=10, passes=25, alpha='auto', per_word_topics=True)\n",
    "\n",
    "# Print the topics\n",
    "topics = lda_model.print_topics()\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# Assign topics to each document\n",
    "def assign_topic(doc):\n",
    "    bow = id2word.doc2bow(doc)\n",
    "    topics = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "    topics = sorted(topics, key=lambda x: -x[1])\n",
    "    return topics[0][0]\n",
    "\n",
    "df_LDA['topic'] = df_LDA['processed_lyrics'].apply(assign_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 lyrics  topic\n",
      "0     yeah tryna call long enough mayb show love may...      8\n",
      "1     club best place find lover bar go mm friend ta...      8\n",
      "2     go time fear one save noth realli got way driv...      1\n",
      "3     ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...      1\n",
      "4     come harri want say goodnight holdin back grav...      1\n",
      "...                                                 ...    ...\n",
      "1616  call phone today ask speak normal somehow stil...      8\n",
      "1617  complic alway way goe feel like wait long wond...      5\n",
      "1618  realli rope time fight life never said goodby ...      1\n",
      "1619  hard part alway seem last forev sometim forget...      1\n",
      "1620  johanna drove slowli citi hudson river fill sn...      8\n",
      "\n",
      "[1621 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_LDA[['lyrics', 'topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>explicit</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "      <th>processed_lyrics</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>200040</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah tryna call long enough mayb show love may...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[yeah, tryna, call, long, enough, mayb, show, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>÷ (Deluxe)</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>233712</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>club best place find lover bar go mm friend ta...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[club, best, place, find, lover, bar, go, mm, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>Divinely Uninspired To A Hellish Extent</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>182160</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>go time fear one save noth realli got way driv...</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.75100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.446</td>\n",
       "      <td>109.891</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, time, fear, one, save, noth, realli, got,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Hollywood's Bleeding</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>157560</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.925</td>\n",
       "      <td>89.960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ayi, ayi, ayi, ayi, ooh, ooh, ooh, ooh, ooh, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Harry's House</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>167303</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>come harri want say goodnight holdin back grav...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.662</td>\n",
       "      <td>173.930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[come, harri, want, say, goodnight, holdin, ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      track_name         artist  \\\n",
       "0                                Blinding Lights     The Weeknd   \n",
       "1                                   Shape of You     Ed Sheeran   \n",
       "2                              Someone You Loved  Lewis Capaldi   \n",
       "3  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "4                                      As It Was   Harry Styles   \n",
       "\n",
       "                                     album release_date  duration  popularity  \\\n",
       "0                              After Hours   2020-03-20    200040          90   \n",
       "1                               ÷ (Deluxe)   2017-03-03    233712          86   \n",
       "2  Divinely Uninspired To A Hellish Extent   2019-05-17    182160          89   \n",
       "3                     Hollywood's Bleeding   2019-09-06    157560          85   \n",
       "4                            Harry's House   2022-05-20    167303          91   \n",
       "\n",
       "   explicit                                             lyrics  danceability  \\\n",
       "0         0  yeah tryna call long enough mayb show love may...         0.514   \n",
       "1         0  club best place find lover bar go mm friend ta...         0.825   \n",
       "2         0  go time fear one save noth realli got way driv...         0.501   \n",
       "3         0  ayi ayi ayi ayi ooh ooh ooh ooh ooh ooh ayi ay...         0.755   \n",
       "4         0  come harri want say goodnight holdin back grav...         0.520   \n",
       "\n",
       "   energy  ...  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0   0.730  ...       0.0598       0.00146          0.000095    0.0897   \n",
       "1   0.652  ...       0.0802       0.58100          0.000000    0.0931   \n",
       "2   0.405  ...       0.0319       0.75100          0.000000    0.1050   \n",
       "3   0.522  ...       0.0575       0.53300          0.000000    0.0685   \n",
       "4   0.731  ...       0.0557       0.34200          0.001010    0.3110   \n",
       "\n",
       "   valence    tempo  time_signature  mood  \\\n",
       "0    0.334  171.005             4.0     0   \n",
       "1    0.931   95.977             4.0     1   \n",
       "2    0.446  109.891             4.0     0   \n",
       "3    0.925   89.960             4.0     1   \n",
       "4    0.662  173.930             4.0     1   \n",
       "\n",
       "                                    processed_lyrics  topic  \n",
       "0  [yeah, tryna, call, long, enough, mayb, show, ...      8  \n",
       "1  [club, best, place, find, lover, bar, go, mm, ...      8  \n",
       "2  [go, time, fear, one, save, noth, realli, got,...      1  \n",
       "3  [ayi, ayi, ayi, ayi, ooh, ooh, ooh, ooh, ooh, ...      1  \n",
       "4  [come, harri, want, say, goodnight, holdin, ba...      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_LDA.shape)\n",
    "df_LDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LDA.to_csv(\"LDA.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
